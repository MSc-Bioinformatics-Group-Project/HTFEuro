{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: easy-entrez in /home/bt211033/.local/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: typing-extensions in /home/bt211033/.local/lib/python3.8/site-packages (from easy-entrez) (4.1.1)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.8/site-packages (from easy-entrez) (2.24.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->easy-entrez) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->easy-entrez) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->easy-entrez) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->easy-entrez) (2020.6.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install easy-entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from easy_entrez import EntrezAPI\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "for line in open ('test.txt','r'):\n",
    "    data = json.loads(line)\n",
    "    identifier = data['refsnp_id']\n",
    "    ids.append(int(identifier))\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrez_api = EntrezAPI(\n",
    "    'your-tool-name',\n",
    "    'e@mail.com',\n",
    "    # optional\n",
    "    return_type='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write script to make dataframe from max_results = 1750 which still has all 3499 results\n",
    "\n",
    "liam = [1,2,3,4,5]\n",
    "liam[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataframe\n",
    "import pandas as pd \n",
    "\n",
    "def retrieve_position(ids):\n",
    "    result = entrez_api.fetch(ids, max_results = 10000, database='snp')\n",
    "    namespaces = {'ns0': 'https://www.ncbi.nlm.nih.gov/SNP/docsum'}\n",
    "\n",
    "    variant_positions = DataFrame([\n",
    "        {\n",
    "            'id': 'rs' + document_summary.get('uid'),\n",
    "            'chromosome': chromosome,\n",
    "            'position': position\n",
    "        }\n",
    "        for document_summary in result.data\n",
    "        for chrom_and_position in document_summary.findall('.//ns0:CHRPOS', namespaces)\n",
    "        for chromosome, position in [chrom_and_position.text.split(':')]\n",
    "    ])\n",
    "    return variant_positions\n",
    "\n",
    "#concatenate dataframe\n",
    "#result = pd.concat(frames)\n",
    "\n",
    "small_dfs = []\n",
    "frame = retrieve_position(ids[190000:200000])\n",
    "small_dfs.append(frame)    \n",
    "    \n",
    "large_df = pd.concat(small_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df = pd.concat(small_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 13840000\n",
    "b = 10000\n",
    "c = a/b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SO WE HAVE 13840613 = 613 LEFT OVER TO ADD ON AT THE END MMMK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE IDS\n",
    "\n",
    "ids = []\n",
    "with open('results.txt','r') as file:\n",
    "    for line in file:\n",
    "        x = int(line.strip())\n",
    "        ids.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13840613"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-9c76c512113e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msmall_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtally\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-c9b4edecb59e>\u001b[0m in \u001b[0;36mretrieve_position\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnamespaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'ns0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'https://www.ncbi.nlm.nih.gov/SNP/docsum'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     variant_positions = DataFrame([\n\u001b[0m\u001b[1;32m      9\u001b[0m         {\n\u001b[1;32m     10\u001b[0m             \u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'rs'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdocument_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-c9b4edecb59e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocument_summary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchrom_and_position\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.//ns0:CHRPOS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchromosome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchrom_and_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     ])\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvariant_positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "small_dfs = []\n",
    "tally = 0\n",
    "x = 10000\n",
    "for i in range(0,20):\n",
    "    frame = retrieve_position(ids[tally:x])\n",
    "    small_dfs.append(frame)\n",
    "    tally += x\n",
    "    x = tally + 10000\n",
    "\n",
    "large_df = pd.concat(small_dfs, ignore_index=True)\n",
    "\n",
    "with open('rsid_position.json','w') as file:\n",
    "    file.write(large_df.to_json(orient = 'split', index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUCKED UP TALLY CALC ABOVE, TRY i:i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dfs = []\n",
    "for i in range(0,10):\n",
    "    try:\n",
    "        frame = retrieve_position(ids[i*10000:(i+1)*10000])\n",
    "        small_dfs.append(frame)\n",
    "    except:\n",
    "        AttributeError\n",
    "large_df = pd.concat(small_dfs, ignore_index=True)\n",
    "\n",
    "with open('rsid_position.json','w') as file:\n",
    "    file.write(large_df.to_json(orient = 'split', index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD TO WRITE TO JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rsid_position.json','w') as file:\n",
    "    file.write(large_df.to_json(orient = 'split', index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/krassowski/easy-entrez#example-obtaining-the-snp-rs-id-number-from-chromosomal-position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD TO COLLAPSE MULTIPLE JSONS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57422734/how-to-merge-multiple-json-files-into-one-file-in-python/57422761"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD TO GET GENE NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespaces = {'ns0': 'https://www.ncbi.nlm.nih.gov/SNP/docsum'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = {}\n",
    "\n",
    "def retrieve_gene_names(ids):\n",
    "    result = entrez_api.fetch(ids, max_results=10000, database='snp')\n",
    "    gene_names = {\n",
    "        'rs' + document_summary.get('uid'): [\n",
    "            element.text\n",
    "            for element in document_summary.findall('.//ns0:GENE_E/ns0:NAME', namespaces)\n",
    "        ]\n",
    "        for document_summary in result.data\n",
    "    }\n",
    "    return gene_names\n",
    "\n",
    "for i in range(0,3):\n",
    "    try:\n",
    "        genedict = retrieve_gene_names(ids[i*10000:(i+1)*10000])\n",
    "        genes.update(genedict)\n",
    "    except:\n",
    "        AttributeError\n",
    "        \n",
    "results = open('gene_names.json','w')\n",
    "json.dump(genes,results)\n",
    "results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open('data.json','w')\n",
    "json.dump(gene_names,a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'this', 'cool': 'me'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liam = {'cool':'me'}\n",
    "x = {'test':'this'}\n",
    "x.update(liam)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEED TO CREATE LIST OF PRESENT POSITIONS IN OUR SAMPLES WITH RESPECTIVE RSIDS & THEN DEMONSTRATE EXTRACT RANGE FROM GENE JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have the list of positions, now need to read this in and iterate over the json as a dictionary to eliminate those which are not present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in positions\n",
    "\n",
    "positions = []\n",
    "with open('chr21.five.populations.all.positions.txt','r') as file:\n",
    "    for line in file:\n",
    "        positions.append(int(line.strip()))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in json with python\n",
    "\n",
    "import json\n",
    "\n",
    "with open('rsid_position.json','r') as f:\n",
    "    data = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rs559', '21', '46129655']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsid_positions = {}\n",
    "for i in range(len(data['data'])):\n",
    "    pull = data['data'][i]\n",
    "    rsid = pull[0]\n",
    "    position = int(pull[2])\n",
    "    rsid_positions[rsid] = position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rsid,position \u001b[38;5;129;01min\u001b[39;00m rsid_positions\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mposition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m:\n\u001b[1;32m      3\u001b[0m         rsid_positions\u001b[38;5;241m.\u001b[39mpop(rsid)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for rsid,position in rsid_positions.copy().items():\n",
    "    if position not in positions:\n",
    "        rsid_positions.pop(rsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "liam = {'a':1,'b':2,'c':3}\n",
    "test = [2,3]\n",
    "\n",
    "for rsid,position in liam.copy().items():\n",
    "    if position not in test:\n",
    "        liam.pop(rsid)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 2, 'c': 3}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write dict to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-50-ec56f4453bf9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [50]\u001b[0;36m\u001b[0m\n\u001b[0;31m    liam = {'id':'position',{'a':1,'b':2,'c':3},}\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "liam = {'id':'position',{'a':1,'b':2,'c':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(liam, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.json','r') as f:\n",
    "    sampledata = json.load(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
